name: 자동 시세 크롤링 및 파싱

on:
  schedule:
    - cron: '0 0 * * *'  # 매일 한국시간 오전 9시 실행
  workflow_dispatch:  # 수동 실행도 가능

jobs:
  crawl-parse-publish:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Fetch today's Band post (원문 저장)
        env:
          BAND_TOKEN: ${{ secrets.BAND_TOKEN }}
          BAND_KEY: ${{ secrets.BAND_KEY }}
        run: |
          python band_to_html.py

      - name: Parse prices from raw HTML (파싱 저장)
        run: |
          python parse_prices.py

      - name: Analyze price and send alert (최저가 기준 분석 및 알림)
        env:
          NTFY_TOPIC: ${{ secrets.NTFY_TOPIC }}
        run: |
          python analyze_and_alert.py

      - name: Build crustacean price history (누적 파일 생성)
        run: |
          python build_crustacean_history.py

      - name: Convert CSV to HTML table
        run: |
          python csv_to_html.py

      - name: Commit and push all changes
        run: |
          git config --global user.name "GitHub Actions"
          git config --global user.email "actions@github.com"
          git add docs/ crustacean_prices.csv
          git commit -m "📈 시세 업데이트 및 누적 기록 자동 반영" || echo "No changes to commit"
          git push
